#!/usr/bin/env python3
"""
Doctor Runner - Read-only sequential lightweight system checker
"""

import json
import os
import sys
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import psutil

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from shared.atomic_io import (append_ndjson_atomic, read_json_atomic,
                              write_json_atomic)
from shared.environment_guardrails import (check_service_pid_lock,
                                           get_repo_paths)


class DoctorRunner:
    """Doctor Runner - ì½ê¸° ì „ìš© ì‹œìŠ¤í…œ ì§„ë‹¨"""
    
    def __init__(self):
        self.paths = get_repo_paths()
        self.run_id = str(uuid.uuid4())[:8]
        self.start_time = time.time()
        self.steps = []
        self.progress_file = self.paths["shared_data"] / "doctor" / f"run_{self.run_id}.ndjson"
        self.summary_file = self.paths["shared_data"] / "doctor" / "summary.json"
        self.lock_file = self.paths["shared_data"] / "doctor" / "doctor.lock"
        self.reports_dir = self.paths["shared_data_reports"]
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        (self.paths["shared_data"] / "doctor").mkdir(parents=True, exist_ok=True)
        (self.paths["shared_data"] / "ops" / "done").mkdir(parents=True, exist_ok=True)
        self.reports_dir.mkdir(parents=True, exist_ok=True)
    
    def run(self, mode: str = "quick") -> bool:
        """Doctor ì‹¤í–‰"""
        try:
            # 1. ë½ íŒŒì¼ ìƒì„± (fail fast if exists)
            if self._create_lock():
                return False
            
            # 2. ì§„í–‰ ìƒí™© íŒŒì¼ ì´ˆê¸°í™”
            self._write_progress({
                "step": "start",
                "status": "running",
                "msg_ko": "Doctor ì§„ë‹¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...",
                "pct": 0,
                "timestamp": time.time()
            })
            
            # 3. ìˆœì°¨ì  ì²´í¬ ì‹¤í–‰
            success = self._run_sequential_checks(mode)
            
            # 4. ê²°ê³¼ ìš”ì•½ ìƒì„±
            self._generate_summary()
            
            # 5. ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
            self._generate_markdown_report()
            
            # 6. ì™„ë£Œ ì²˜ë¦¬
            self._cleanup()
            
            return success
            
        except Exception as e:
            self._write_progress({
                "step": "error",
                "status": "fail",
                "msg_ko": f"Doctor ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                "timestamp": time.time()
            })
            self._cleanup()
            return False
    
    def _create_lock(self) -> bool:
        """ë½ íŒŒì¼ ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‹¤íŒ¨)"""
        if self.lock_file.exists():
            print(f"âŒ Doctorê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤: {self.lock_file}")
            return True
        
        try:
            lock_data = {
                "run_id": self.run_id,
                "started_at": time.time(),
                "pid": os.getpid()
            }
            write_json_atomic(self.lock_file, lock_data)
            return False
        except Exception as e:
            print(f"âŒ ë½ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return True
    
    def _write_progress(self, data: Dict[str, Any]):
        """ì§„í–‰ ìƒí™© ê¸°ë¡"""
        data["run_id"] = self.run_id
        append_ndjson_atomic(self.progress_file, data)
    
    def _run_sequential_checks(self, mode: str) -> bool:
        """ìˆœì°¨ì  ì²´í¬ ì‹¤í–‰"""
        checks = [
            ("env_parity", self._check_environment_parity),
            ("duplicate_instances", self._check_duplicate_instances),
            ("health_snapshot", self._check_health_snapshot),
            ("feeder", self._check_feeder),
            ("uds", self._check_uds),
            ("ares", self._check_ares),
            ("trader_guardrails", self._check_trader_guardrails),
            ("account_snapshot", self._check_account_snapshot),
            ("autoheal", self._check_autoheal),
            ("resources", self._check_resources)
        ]
        
        total_steps = len(checks)
        all_passed = True
        
        for i, (step_name, check_func) in enumerate(checks):
            pct = int((i / total_steps) * 100)
            
            # running ìƒíƒœ ê¸°ë¡
            self._write_progress({
                "step": step_name,
                "status": "running",
                "msg_ko": self._get_step_message(step_name),
                "pct": pct,
                "timestamp": time.time()
            })
            
            # ì²´í¬ ì‹¤í–‰
            try:
                success, details = check_func()
                status = "pass" if success else "fail"
                
                if not success:
                    all_passed = False
                
                # ê²°ê³¼ ê¸°ë¡
                result = {
                    "step": step_name,
                    "status": status,
                    "pct": pct,
                    "timestamp": time.time()
                }
                
                if details:
                    result.update(details)
                
                self._write_progress(result)
                self.steps.append(result)
                
                # 50-100ms ê°„ê²©
                time.sleep(0.075)
                
            except Exception as e:
                # ì˜¤ë¥˜ ì²˜ë¦¬
                self._write_progress({
                    "step": step_name,
                    "status": "fail",
                    "reason": str(e),
                    "pct": pct,
                    "timestamp": time.time()
                })
                all_passed = False
                self.steps.append({
                    "step": step_name,
                    "status": "fail",
                    "reason": str(e),
                    "pct": pct
                })
        
        return all_passed
    
    def _get_step_message(self, step_name: str) -> str:
        """ë‹¨ê³„ë³„ í•œêµ­ì–´ ë©”ì‹œì§€"""
        messages = {
            "env_parity": "í™˜ê²½ ì„¤ì • ë° ë””ë ‰í† ë¦¬ ì ê²€ ì¤‘...",
            "duplicate_instances": "ì¤‘ë³µ í”„ë¡œì„¸ìŠ¤ í™•ì¸ ì¤‘...",
            "health_snapshot": "í—¬ìŠ¤ ìŠ¤ëƒ…ìƒ· ë¶„ì„ ì¤‘...",
            "feeder": "ì‹œì„¸ ìˆ˜ì§‘/ìŠ¤ëƒ…ìƒ· ì“°ê¸° ì ê²€...",
            "uds": "ì‚¬ìš©ì ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ìƒíƒœ í™•ì¸...",
            "ares": "ARES ì—”ì§„ ì‹ í˜¸ ê²€ì¦ ì¤‘...",
            "trader_guardrails": "íŠ¸ë ˆì´ë” ê°€ë“œë ˆì¼ ì ê²€...",
            "account_snapshot": "ê³„ì¢Œ ìŠ¤ëƒ…ìƒ· ìœ íš¨ì„± ê²€ì‚¬...",
            "autoheal": "ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸...",
            "resources": "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§..."
        }
        return messages.get(step_name, f"{step_name} ì ê²€ ì¤‘...")
    
    def _check_environment_parity(self) -> Tuple[bool, Dict[str, Any]]:
        """í™˜ê²½ íŒ¨ë¦¬í‹° ì²´í¬"""
        try:
            # repo root í™•ì¸
            expected_root = self.paths["repo_root"]
            current_root = Path.cwd().absolute()
            
            if current_root != expected_root:
                return False, {
                    "reason": f"Wrong working directory: {current_root} != {expected_root}",
                    "hint_ko": "í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”."
                }
            
            # venv ê²½ë¡œ í™•ì¸
            venv_python = self.paths["venv_python"]
            if not venv_python.exists():
                return False, {
                    "reason": f"Virtual environment not found: {venv_python}",
                    "hint_ko": "ê°€ìƒí™˜ê²½ì„ ìƒì„±í•˜ê±°ë‚˜ í™œì„±í™”í•˜ì„¸ìš”."
                }
            
            # í•„ìˆ˜ ë””ë ‰í† ë¦¬ í™•ì¸
            required_dirs = ["shared_data", "logs", "shared_data/pids"]
            missing_dirs = []
            
            for dir_name in required_dirs:
                dir_path = self.paths.get(dir_name.replace("/", "_"), Path(dir_name))
                if not dir_path.exists() or not os.access(dir_path, os.W_OK):
                    missing_dirs.append(str(dir_path))
            
            if missing_dirs:
                return False, {
                    "reason": f"Missing or unwritable directories: {missing_dirs}",
                    "hint_ko": "í•„ìˆ˜ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  ì“°ê¸° ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”."
                }
            
            return True, {"metric": {"repo_root": str(expected_root), "venv": str(venv_python)}}
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_duplicate_instances(self) -> Tuple[bool, Dict[str, Any]]:
        """ì¤‘ë³µ ì¸ìŠ¤í„´ìŠ¤ ì²´í¬"""
        try:
            services = ["feeder", "trader", "ares", "uds", "autoheal"]
            duplicates = []
            running_services = []
            
            for service in services:
                is_running, pid = check_service_pid_lock(service)
                if is_running:
                    running_services.append(service)
                    
                    # ì‹¤ì œ í”„ë¡œì„¸ìŠ¤ í™•ì¸
                    try:
                        process = psutil.Process(pid)
                        cmdline = " ".join(process.cmdline())
                        if service not in cmdline:
                            duplicates.append(f"{service}: PID {pid} not matching")
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        # ìŠ¤í…Œì¼ PID íŒŒì¼
                        duplicates.append(f"{service}: stale PID {pid}")
            
            if duplicates:
                return False, {
                    "reason": f"Duplicate or stale processes: {duplicates}",
                    "hint_ko": "ì¤‘ë³µ í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”.",
                    "metric": {"duplicates": len(duplicates), "running": len(running_services)}
                }
            
            return True, {"metric": {"running_services": running_services, "total": len(services)}}
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "í”„ë¡œì„¸ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_health_snapshot(self) -> Tuple[bool, Dict[str, Any]]:
        """í—¬ìŠ¤ ìŠ¤ëƒ…ìƒ· ì²´í¬"""
        try:
            health_file = self.paths["shared_data"] / "health.json"
            
            if not health_file.exists():
                return False, {
                    "reason": "health.json not found",
                    "hint_ko": "í—¬ìŠ¤ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }
            
            # íŒŒì¼ ë‚˜ì´ í™•ì¸
            file_age = time.time() - health_file.stat().st_mtime
            if file_age > 15:
                return False, {
                    "reason": f"health.json age {file_age:.1f}s > 15s",
                    "hint_ko": "í—¬ìŠ¤ íŒŒì¼ì´ ì˜¤ë˜ë˜ì—ˆìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                }
            
            # JSON íŒŒì‹± í™•ì¸
            health_data = read_json_atomic(health_file, {})
            if not health_data:
                return False, {
                    "reason": "health.json parse failed",
                    "hint_ko": "í—¬ìŠ¤ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”."
                }
            
            return True, {"metric": {"file_age_sec": file_age, "components": len(health_data)}}
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "í—¬ìŠ¤ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_feeder(self) -> Tuple[bool, Dict[str, Any]]:
        """Feeder ì²´í¬"""
        try:
            # ìŠ¤ëƒ…ìƒ· íŒŒì¼ í™•ì¸
            snapshot_files = [
                self.paths["shared_data"] / "state_bus.json",
                self.paths["shared_data"] / "databus_snapshot.json"
            ]
            
            snapshot_age = float('inf')
            snapshot_file = None
            
            for file_path in snapshot_files:
                if file_path.exists():
                    age = time.time() - file_path.stat().st_mtime
                    if age < snapshot_age:
                        snapshot_age = age
                        snapshot_file = file_path.name
            
            if snapshot_age > 5:
                return False, {
                    "reason": f"snapshot age {snapshot_age:.1f}s > 5s",
                    "hint_ko": "Feeder ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”.",
                    "metric": {"snapshot_age_sec": snapshot_age}
                }
            
            # ë¡œê·¸ íŒŒì¼ í™•ì¸ (ìµœê·¼ 120ì¤„)
            log_files = [
                self.paths["logs"] / "feeder.log",
                self.paths["shared_data"] / "logs" / "feeder.log"
            ]
            
            win_errors = []
            for log_file in log_files:
                if log_file.exists():
                    try:
                        with open(log_file, 'r', encoding='utf-8') as f:
                            lines = f.readlines()
                            recent_lines = lines[-120:] if len(lines) > 120 else lines
                            
                            for line in recent_lines:
                                if "WinError 183" in line or "WinError 32" in line:
                                    win_errors.append(line.strip())
                    except Exception:
                        pass
            
            if win_errors:
                return False, {
                    "reason": f"WinError found in logs: {len(win_errors)} instances",
                    "hint_ko": "íŒŒì¼ ë½ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ì„¸ìš”.",
                    "metric": {"win_errors": len(win_errors)}
                }
            
            return True, {
                "metric": {
                    "snapshot_age_sec": snapshot_age,
                    "snapshot_file": snapshot_file,
                    "win_errors": 0
                }
            }
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "Feeder ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_uds(self) -> Tuple[bool, Dict[str, Any]]:
        """UDS ì²´í¬"""
        try:
            health_data = read_json_atomic(self.paths["shared_data"] / "health.json", {})
            uds_health = health_data.get("uds", {})
            
            if not uds_health:
                return False, {
                    "reason": "UDS health data not found",
                    "hint_ko": "UDS ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”."
                }
            
            heartbeat_age = uds_health.get("heartbeat_age_sec", 999)
            state = uds_health.get("state", "UNKNOWN")
            
            if heartbeat_age > 50:
                return False, {
                    "reason": f"heartbeat_age_sec={heartbeat_age} > 50",
                    "hint_ko": "UDS ì¬ì‹œì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                    "metric": {"heartbeat_age_sec": heartbeat_age, "state": state}
                }
            
            if state != "CONNECTED":
                return False, {
                    "reason": f"UDS state={state} != CONNECTED",
                    "hint_ko": "UDS ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                    "metric": {"heartbeat_age_sec": heartbeat_age, "state": state}
                }
            
            return True, {"metric": {"heartbeat_age_sec": heartbeat_age, "state": state}}
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "UDS ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_ares(self) -> Tuple[bool, Dict[str, Any]]:
        """ARES ì²´í¬"""
        try:
            # fallback í”Œë˜ê·¸ í™•ì¸
            allow_default = os.getenv("TEST_ALLOW_DEFAULT_SIGNAL", "false").lower() == "true"
            
            if allow_default:
                return True, {"metric": {"fallback_allowed": True, "signals": "default allowed"}}
            
            # ì‹ í˜¸ íŒŒì¼ í™•ì¸
            signals_file = self.paths["shared_data"] / "signals" / "ares_signals.json"
            if not signals_file.exists():
                return False, {
                    "reason": "ARES signals file not found",
                    "hint_ko": "ARES ì—”ì§„ì„ ì‹œì‘í•˜ì„¸ìš”."
                }
            
            # íŒŒì¼ ë‚˜ì´ í™•ì¸ (10ë¶„)
            file_age = time.time() - signals_file.stat().st_mtime
            if file_age > 600:
                return False, {
                    "reason": f"signals file age {file_age:.1f}s > 600s",
                    "hint_ko": "ARES ì—”ì§„ì´ ë©ˆì¶˜ ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
                    "metric": {"file_age_sec": file_age}
                }
            
            # ì‹¤ì œ ì‹ í˜¸ í™•ì¸
            signals_data = read_json_atomic(signals_file, {})
            real_signals = 0
            
            for symbol, signal_data in signals_data.items():
                if isinstance(signal_data, dict):
                    confidence = signal_data.get("confidence", 0)
                    if confidence > 50:  # 50% ì´ìƒ ì‹ ë¢°ë„
                        real_signals += 1
            
            if real_signals == 0:
                return False, {
                    "reason": "No real signals found",
                    "hint_ko": "ARESê°€ ì‹¤ì œ ì‹ í˜¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    "metric": {"real_signals": 0, "total_signals": len(signals_data)}
                }
            
            return True, {
                "metric": {
                    "real_signals": real_signals,
                    "total_signals": len(signals_data),
                    "file_age_sec": file_age
                }
            }
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "ARES ì—”ì§„ì„ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_trader_guardrails(self) -> Tuple[bool, Dict[str, Any]]:
        """Trader ê°€ë“œë ˆì¼ ì²´í¬"""
        try:
            health_data = read_json_atomic(self.paths["shared_data"] / "health.json", {})
            trader_health = health_data.get("trader", {})
            
            if not trader_health:
                return False, {
                    "reason": "Trader health data not found",
                    "hint_ko": "Trader ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”."
                }
            
            issues = []
            
            # UDS age í™•ì¸
            uds_age = trader_health.get("uds_age", 999)
            if uds_age > 60:
                issues.append(f"uds_age={uds_age} > 60")
            
            # Filters state í™•ì¸
            filters_state = trader_health.get("filters", "STALE")
            if filters_state != "FRESH":
                issues.append(f"filters_state={filters_state} != FRESH")
            
            # Circuit breaker í™•ì¸
            circuit_file = self.paths["shared_data"] / "circuit_breaker.json"
            if circuit_file.exists():
                circuit_data = read_json_atomic(circuit_file, {})
                if circuit_data.get("active", False):
                    issues.append("circuit_breaker=ON")
            
            # Account snapshot age í™•ì¸
            account_file = self.paths["shared_data"] / "account_snapshot.json"
            if account_file.exists():
                account_age = time.time() - account_file.stat().st_mtime
                if account_age > 180:
                    issues.append(f"account_snapshot_age={account_age:.1f}s > 180s")
            
            # Health file recency í™•ì¸
            health_age = trader_health.get("last_update", 0)
            if health_age > 0:
                age = time.time() - health_age
                if age > 15:
                    issues.append(f"health_age={age:.1f}s > 15s")
            
            if issues:
                return False, {
                    "reason": f"Guardrail violations: {issues}",
                    "hint_ko": "Trader ê°€ë“œë ˆì¼ì„ í™•ì¸í•˜ê³  í•„ìš”í•œ ì¡°ì¹˜ë¥¼ ì·¨í•˜ì„¸ìš”.",
                    "metric": {"violations": len(issues), "details": issues}
                }
            
            return True, {"metric": {"violations": 0, "status": "all_clear"}}
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "Trader ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_account_snapshot(self) -> Tuple[bool, Dict[str, Any]]:
        """ê³„ì¢Œ ìŠ¤ëƒ…ìƒ· ì²´í¬"""
        try:
            account_file = self.paths["shared_data"] / "account_snapshot.json"
            
            if not account_file.exists():
                return False, {
                    "reason": "account_snapshot.json not found",
                    "hint_ko": "ê³„ì¢Œ ìŠ¤ëƒ…ìƒ· ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”."
                }
            
            # íŒŒì¼ ë‚˜ì´ í™•ì¸
            file_age = time.time() - account_file.stat().st_mtime
            if file_age > 180:
                return False, {
                    "reason": f"account_snapshot age {file_age:.1f}s > 180s",
                    "hint_ko": "ê³„ì¢Œ ìŠ¤ëƒ…ìƒ· ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                    "metric": {"file_age_sec": file_age}
                }
            
            # JSON íŒŒì‹± ë° í•„ìˆ˜ í•„ë“œ í™•ì¸
            account_data = read_json_atomic(account_file, {})
            if not account_data:
                return False, {
                    "reason": "account_snapshot.json parse failed",
                    "hint_ko": "ê³„ì¢Œ ìŠ¤ëƒ…ìƒ· íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”."
                }
            
            # equity/free í•„ë“œ í™•ì¸
            has_equity = "equity" in account_data or any("equity" in str(key).lower() for key in account_data.keys())
            has_free = "free" in account_data or any("free" in str(key).lower() for key in account_data.keys())
            
            if not (has_equity or has_free):
                return False, {
                    "reason": "equity/free fields not found in account snapshot",
                    "hint_ko": "ê³„ì¢Œ ì •ë³´ê°€ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "metric": {"file_age_sec": file_age, "fields": list(account_data.keys())}
                }
            
            return True, {
                "metric": {
                    "file_age_sec": file_age,
                    "has_equity": has_equity,
                    "has_free": has_free,
                    "fields": list(account_data.keys())
                }
            }
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "ê³„ì¢Œ ìŠ¤ëƒ…ìƒ·ì„ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_autoheal(self) -> Tuple[bool, Dict[str, Any]]:
        """Auto-Heal ì²´í¬"""
        try:
            health_data = read_json_atomic(self.paths["shared_data"] / "health.json", {})
            autoheal_health = health_data.get("autoheal", {})
            
            if not autoheal_health:
                return False, {
                    "reason": "Auto-Heal health data not found",
                    "hint_ko": "Auto-Heal ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”."
                }
            
            # ì»´í¬ë„ŒíŠ¸ ë“±ë¡ í™•ì¸
            if "component" not in autoheal_health:
                return False, {
                    "reason": "Auto-Heal component not registered",
                    "hint_ko": "Auto-Healì´ ì‹œìŠ¤í…œì— ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }
            
            # heartbeat í™•ì¸
            heartbeat_age = autoheal_health.get("last_update", 0)
            if heartbeat_age > 0:
                age = time.time() - heartbeat_age
                if age > 30:
                    return False, {
                        "reason": f"Auto-Heal heartbeat age {age:.1f}s > 30s",
                        "hint_ko": "Auto-Heal ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                        "metric": {"heartbeat_age_sec": age}
                    }
            
            # watching list í™•ì¸
            watching = autoheal_health.get("watching", [])
            expected_services = ["feeder", "trader", "ares", "uds"]
            missing_watches = [svc for svc in expected_services if svc not in watching]
            
            if missing_watches:
                return False, {
                    "reason": f"Missing watched services: {missing_watches}",
                    "hint_ko": "Auto-Healì´ ëª¨ë“  ì„œë¹„ìŠ¤ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    "metric": {"watching": watching, "missing": missing_watches}
                }
            
            return True, {
                "metric": {
                    "heartbeat_age_sec": age if heartbeat_age > 0 else 0,
                    "watching_services": watching,
                    "total_watched": len(watching)
                }
            }
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "Auto-Heal ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    def _check_resources(self) -> Tuple[bool, Dict[str, Any]]:
        """ë¦¬ì†ŒìŠ¤ ì²´í¬"""
        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # ë””ìŠ¤í¬ ì—¬ìœ ê³µê°„
            disk_usage = psutil.disk_usage(str(self.paths["repo_root"]))
            free_gb = disk_usage.free / (1024**3)
            
            # í•¸ë“¤ ìˆ˜ (ê°„ë‹¨í•œ ì¶”ì •)
            try:
                process = psutil.Process()
                handle_count = process.num_handles() if hasattr(process, 'num_handles') else 0
            except:
                handle_count = 0
            
            warnings = []
            
            if memory_percent > 90:
                warnings.append(f"memory={memory_percent:.1f}%")
            
            if free_gb < 1.0:
                warnings.append(f"disk_free={free_gb:.1f}GB")
            
            if handle_count > 1000:
                warnings.append(f"handles={handle_count}")
            
            if warnings:
                return False, {
                    "reason": f"Resource warnings: {warnings}",
                    "hint_ko": "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                    "metric": {
                        "memory_percent": memory_percent,
                        "disk_free_gb": free_gb,
                        "handle_count": handle_count
                    }
                }
            
            return True, {
                "metric": {
                    "memory_percent": memory_percent,
                    "disk_free_gb": free_gb,
                    "handle_count": handle_count
                }
            }
            
        except Exception as e:
            return False, {"reason": str(e), "hint_ko": "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    def _generate_summary(self):
        """ìš”ì•½ ìƒì„±"""
        try:
            failed_steps = [step for step in self.steps if step.get("status") == "fail"]
            passed_steps = [step for step in self.steps if step.get("status") == "pass"]
            
            # ì£¼ìš” ì›ì¸ ë¶„ì„
            top_causes = []
            for step in failed_steps:
                reason = step.get("reason", "Unknown")
                top_causes.append({
                    "step": step.get("step"),
                    "reason": reason,
                    "hint_ko": step.get("hint_ko", "ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                })
            
            # ë‹¤ìŒ ì•¡ì…˜
            next_actions = []
            if failed_steps:
                next_actions.append("ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ë“¤ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.")
                next_actions.append("ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
                next_actions.append("ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìƒíƒœë¥¼ ì ê²€í•˜ì„¸ìš”.")
            else:
                next_actions.append("ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.")
                next_actions.append("ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ì„¸ìš”.")
                next_actions.append("ë¡œê·¸ ë¡œí…Œì´ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            summary = {
                "run_id": self.run_id,
                "timestamp": time.time(),
                "duration_sec": time.time() - self.start_time,
                "overall_status": "pass" if not failed_steps else "fail",
                "steps": self.steps,
                "summary": {
                    "total_steps": len(self.steps),
                    "passed": len(passed_steps),
                    "failed": len(failed_steps)
                },
                "top_causes": top_causes,
                "next_actions_ko": next_actions
            }
            
            write_json_atomic(self.summary_file, summary)
            
        except Exception as e:
            print(f"Summary generation failed: {e}")
    
    def _generate_markdown_report(self):
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„± - Canonical path with atomic write"""
        import logging
        logger = logging.getLogger(__name__)

        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # Canonical paths: latest.md and timestamped backup
            canonical_dir = self.reports_dir / "stack_doctor"
            canonical_dir.mkdir(parents=True, exist_ok=True)

            latest_report = canonical_dir / "latest.md"
            timestamped_report = self.reports_dir / f"stack_doctor_{timestamp}.md"

            failed_steps = [step for step in self.steps if step.get("status") == "fail"]
            passed_steps = [step for step in self.steps if step.get("status") == "pass"]

            # ê²°ë¡  3ì¤„
            if not failed_steps:
                conclusion = [
                    "âœ… ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
                    "ğŸ¯ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œì´ ì•ˆì „í•˜ê²Œ ìš´ì˜ë  ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                    "ğŸ“Š ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ì„¸ìš”."
                ]
            else:
                conclusion = [
                    f"âŒ {len(failed_steps)}ê°œ í•­ëª©ì—ì„œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "ğŸš¨ ìë™ë§¤ë§¤ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.",
                    "ğŸ”§ ì•„ë˜ ê¶Œì¥ ì¡°ì¹˜ë¥¼ ë”°ë¼ ì‹œìŠ¤í…œì„ ë³µêµ¬í•˜ì„¸ìš”."
                ]

            # ì‹ í˜¸ë“± í‘œ
            status_emoji = "ğŸŸ¢" if not failed_steps else "ğŸ”´"
            overall_status = "ì •ìƒ" if not failed_steps else "ë¬¸ì œ ë°œê²¬"

            # ê·¼ê±° (ê° í•­ëª© TTL/ì‹¤ì¸¡ê°’)
            evidence = []
            for step in self.steps:
                step_name = step.get("step", "unknown")
                status = step.get("status", "unknown")
                reason = step.get("reason", "")
                metric = step.get("metric", {})
                hint = step.get("hint_ko", "")

                status_icon = "âœ…" if status == "pass" else "âŒ" if status == "fail" else "â³"
                evidence.append(f"- {status_icon} **{step_name}**: {reason or 'OK'}")
                if metric:
                    metric_str = ", ".join([f"{k}={v}" for k, v in metric.items()])
                    evidence.append(f"  - ì¸¡ì •ê°’: {metric_str}")
                if hint:
                    evidence.append(f"  - ğŸ’¡ {hint}")

            # ë°”ë¡œ í•  ì¼ 3ê°œ
            actions = []
            if failed_steps:
                # ì‹¤íŒ¨í•œ í•­ëª©ë³„ ì•¡ì…˜
                for step in failed_steps[:3]:  # ìµœëŒ€ 3ê°œ
                    step_name = step.get("step", "")
                    hint = step.get("hint_ko", "ìƒì„¸ í™•ì¸ í•„ìš”")
                    actions.append(f"1. **{step_name}**: {hint}")
            else:
                actions = [
                    "1. **ëª¨ë‹ˆí„°ë§**: ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì§€ì†ì ìœ¼ë¡œ ê´€ì°°í•˜ì„¸ìš”.",
                    "2. **ë¡œê·¸ ê´€ë¦¬**: ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.",
                    "3. **ë°±ì—…**: ì •ê¸°ì ì¸ ì„¤ì • íŒŒì¼ ë°±ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
                ]

            # ë³´ê³ ì„œ ì‘ì„± (ensure non-empty even on "no issues")
            report_content = f"""# Stack Doctor Report - {timestamp}

## ğŸ¯ ê²°ë¡ 
{chr(10).join(conclusion)}

## ğŸš¦ ì „ì²´ ìƒíƒœ
| í•­ëª© | ìƒíƒœ | ì„¸ë¶€ì‚¬í•­ |
|------|------|----------|
| **ì „ì²´ ì‹œìŠ¤í…œ** | {status_emoji} {overall_status} | {len(passed_steps)}/{len(self.steps)} í•­ëª© í†µê³¼ |
| **ì‹¤í–‰ ì‹œê°„** | â±ï¸ | {time.time() - self.start_time:.1f}ì´ˆ |
| **ì§„ë‹¨ ID** | ğŸ” | {self.run_id} |

## ğŸ“Š ìƒì„¸ ê·¼ê±°
{chr(10).join(evidence)}

## ğŸ”§ ë°”ë¡œ í•  ì¼
{chr(10).join(actions)}

---
*ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Doctor Runner v1.0*
"""

            # Atomic write to both locations (UTF-8, no BOM)
            from shared.atomic_io import write_text_atomic

            # Write to canonical latest.md
            success_latest = write_text_atomic(latest_report, report_content, encoding='utf-8')
            if success_latest:
                logger.info(f"report_writer: wrote canonical report to {latest_report}")

            # Write to timestamped backup
            success_timestamped = write_text_atomic(timestamped_report, report_content, encoding='utf-8')
            if success_timestamped:
                logger.info(f"report_writer: wrote timestamped report to {timestamped_report}")

        except Exception as e:
            print(f"Markdown report generation failed: {e}")
    
    def _cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        try:
            # ë½ íŒŒì¼ ì œê±°
            if self.lock_file.exists():
                self.lock_file.unlink()
            
            # ëª…ë ¹ì–´ íŒŒì¼ì„ doneìœ¼ë¡œ ì´ë™
            trigger_file = self.paths["shared_data"] / "ops" / "doctor.run"
            if trigger_file.exists():
                done_file = self.paths["shared_data"] / "ops" / "done" / f"doctor_{self.run_id}.json"
                trigger_file.rename(done_file)
            
        except Exception as e:
            print(f"Cleanup failed: {e}")


def run_doctor():
    """Doctor ì‹¤í–‰ (ì™¸ë¶€ì—ì„œ í˜¸ì¶œ)"""
    trigger_file = Path("shared_data/ops/doctor.run")
    
    if not trigger_file.exists():
        return False
    
    try:
        # íŠ¸ë¦¬ê±° íŒŒì¼ ì½ê¸°
        trigger_data = read_json_atomic(trigger_file, {})
        mode = trigger_data.get("mode", "quick")
        
        # Doctor ì‹¤í–‰
        runner = DoctorRunner()
        success = runner.run(mode)
        
        return success
        
    except Exception as e:
        print(f"Doctor execution failed: {e}")
        return False


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
    print("ğŸ” Doctor Runner - ë…ë¦½ ì‹¤í–‰")
    
    # í…ŒìŠ¤íŠ¸ìš© íŠ¸ë¦¬ê±° íŒŒì¼ ìƒì„±
    test_trigger = Path("shared_data/ops/doctor.run")
    test_trigger.parent.mkdir(parents=True, exist_ok=True)
    
    write_json_atomic(test_trigger, {"mode": "quick"})
    
    success = run_doctor()
    
    if success:
        print("\nğŸ‰ Doctor ì§„ë‹¨ ì™„ë£Œ - ëª¨ë“  í•­ëª© í†µê³¼!")
    else:
        print("\nâŒ Doctor ì§„ë‹¨ ì™„ë£Œ - ì¼ë¶€ í•­ëª© ì‹¤íŒ¨")
