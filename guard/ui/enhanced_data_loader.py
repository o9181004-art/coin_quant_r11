#!/usr/bin/env python3
"""
í–¥ìƒëœ ë°ì´í„° ë¡œë” - ì²« ê³„ì‚° ì‹œë“œ, ë¬´ê²°ì„± ê²€ì¦, stale ë¡œì§ ê°•í™”
"""

import json
import logging
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

import streamlit as st

from .file_watcher import get_global_watcher


@dataclass
class DataIntegrityResult:
    """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ê²°ê³¼"""
    is_valid: bool
    errors: List[str]
    warnings: List[str]
    symbol_count: int
    timestamp: float
    age_sec: float


class EnhancedDataLoader:
    """í–¥ìƒëœ ë°ì´í„° ë¡œë”"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.watcher = get_global_watcher()
        
        # Stale threshold ê°•í™” (30ì´ˆ â†’ 15ì´ˆ)
        self.stale_threshold = 15.0
        self.heartbeat_threshold = 20.0
        
        # ì²« ê³„ì‚° ì‹œë“œë¥¼ ìœ„í•œ ìƒíƒœ
        self.first_tick_seeded: Dict[str, bool] = {}
        self.last_snapshot_data: Optional[Dict] = None
    
    def validate_data_integrity(self, data: Dict, data_type: str = "snapshot") -> DataIntegrityResult:
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        errors = []
        warnings = []
        
        try:
            # JSON íŒŒì‹± í™•ì¸
            if not isinstance(data, dict):
                errors.append("Data is not a dictionary")
                return DataIntegrityResult(False, errors, warnings, 0, 0, 0)
            
            # í•„ìˆ˜ í‚¤ í™•ì¸
            if data_type == "snapshot":
                required_keys = ['timestamp', 'meta', 'ohlcv_1m']
            elif data_type == "health":
                required_keys = ['heartbeat', 'symbols']
            else:
                required_keys = ['timestamp']
            
            for key in required_keys:
                if key not in data:
                    errors.append(f"Missing required key: {key}")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸
            timestamp = data.get('timestamp', 0)
            if timestamp <= 0:
                errors.append("Invalid timestamp")
            
            current_time = time.time()
            age_sec = current_time - timestamp
            
            # Stale ë°ì´í„° ê²½ê³ 
            if age_sec > self.stale_threshold:
                warnings.append(f"Stale data: {age_sec:.1f}s > {self.stale_threshold}s")
            
            # ì‹¬ë³¼ ìˆ˜ í™•ì¸
            symbol_count = 0
            if data_type == "snapshot":
                ohlcv_data = data.get('ohlcv_1m', {})
                symbol_count = len(ohlcv_data)
                
                if symbol_count < 5:
                    warnings.append(f"Low symbol count: {symbol_count}")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì§„í–‰ í™•ì¸
            if hasattr(self, '_last_timestamp'):
                if timestamp <= self._last_timestamp:
                    warnings.append(f"Timestamp not progressing: {timestamp} <= {self._last_timestamp}")
            
            self._last_timestamp = timestamp
            
            is_valid = len(errors) == 0
            
            return DataIntegrityResult(
                is_valid=is_valid,
                errors=errors,
                warnings=warnings,
                symbol_count=symbol_count,
                timestamp=timestamp,
                age_sec=age_sec
            )
            
        except Exception as e:
            errors.append(f"Validation error: {e}")
            return DataIntegrityResult(False, errors, warnings, 0, 0, 0)
    
    def seed_first_tick(self, symbol: str, data: Dict) -> bool:
        """ì²« í‹± ì‹œë“œ (2-tick ì§€ì—° ë°©ì§€)"""
        if symbol in self.first_tick_seeded:
            return False
        
        try:
            # ì‹¬ë³¼ ë°ì´í„° í™•ì¸
            ohlcv_data = data.get('ohlcv_1m', {})
            if symbol not in ohlcv_data:
                return False
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¼ê´€ì„± í™•ì¸
            current_time = time.time()
            snapshot_ts = data.get('timestamp', 0)
            
            # 5ë¶„ ì´ë‚´ ë°ì´í„°ë§Œ ì‚¬ìš©
            if current_time - snapshot_ts > 300:
                return False
            
            # ì‹œë“œ ì™„ë£Œ
            self.first_tick_seeded[symbol] = True
            self.logger.info(f"Seeded first tick for {symbol}")
            return True
            
        except Exception as e:
            self.logger.error(f"First tick seed error for {symbol}: {e}")
            return False
    
    def load_databus_snapshot(self) -> Tuple[Optional[Dict], DataIntegrityResult]:
        """databus_snapshot.json ë¡œë“œ (ë¬´ê²°ì„± ê²€ì¦ í¬í•¨)"""
        try:
            snapshot_file = Path("shared_data/databus_snapshot.json")
            if not snapshot_file.exists():
                return None, DataIntegrityResult(False, ["File not found"], [], 0, 0, 0)
            
            with open(snapshot_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ë¬´ê²°ì„± ê²€ì¦
            integrity_result = self.validate_data_integrity(data, "snapshot")
            
            if integrity_result.is_valid:
                self.last_snapshot_data = data
                
                # ê²½ê³  ë¡œê·¸ (ì—ëŸ¬ê°€ ì•„ë‹Œ ê²½ê³ ë§Œ)
                for warning in integrity_result.warnings:
                    self.logger.warning(f"Data integrity warning: {warning}")
                
                return data, integrity_result
            else:
                # ì—ëŸ¬ ë¡œê·¸
                for error in integrity_result.errors:
                    self.logger.error(f"Data integrity error: {error}")
                
                return None, integrity_result
                
        except Exception as e:
            error_msg = f"Failed to load databus snapshot: {e}"
            self.logger.error(error_msg)
            return None, DataIntegrityResult(False, [error_msg], [], 0, 0, 0)
    
    def load_health_data(self) -> Tuple[Optional[Dict], DataIntegrityResult]:
        """health.json ë¡œë“œ (ë¬´ê²°ì„± ê²€ì¦ í¬í•¨)"""
        try:
            health_file = Path("shared_data/health.json")
            if not health_file.exists():
                return None, DataIntegrityResult(False, ["File not found"], [], 0, 0, 0)
            
            with open(health_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ë¬´ê²°ì„± ê²€ì¦
            integrity_result = self.validate_data_integrity(data, "health")
            
            if integrity_result.is_valid:
                # Heartbeat ì§€ì—° í™•ì¸
                heartbeat_ts = data.get('heartbeat', {}).get('ts', 0)
                current_time = time.time()
                lag_sec = current_time - heartbeat_ts
                
                if lag_sec > self.heartbeat_threshold:
                    integrity_result.warnings.append(f"Feeder lag: {lag_sec:.1f}s > {self.heartbeat_threshold}s")
                
                return data, integrity_result
            else:
                return None, integrity_result
                
        except Exception as e:
            error_msg = f"Failed to load health data: {e}"
            self.logger.error(error_msg)
            return None, DataIntegrityResult(False, [error_msg], [], 0, 0, 0)
    
    def load_ares_signals(self) -> Dict[str, Any]:
        """ARES ì‹ í˜¸ ë¡œë“œ (ì²« ê³„ì‚° ì‹œë“œ í¬í•¨)"""
        signals = {}
        try:
            ares_dir = Path("shared_data/ares")
            if not ares_dir.exists():
                return signals
            
            for signal_file in ares_dir.glob("*.json"):
                try:
                    with open(signal_file, "r", encoding="utf-8") as f:
                        signal_data = json.load(f)
                        symbol = signal_file.stem.upper()
                        
                        # ì²« ê³„ì‚° ì‹œë“œ ì‹œë„
                        if self.last_snapshot_data:
                            self.seed_first_tick(symbol, self.last_snapshot_data)
                        
                        # ìƒˆë¡œìš´ ARES ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬
                        if "signals" in signal_data and signal_data["signals"]:
                            # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì‹ í˜¸ ì„ íƒ
                            best_signal = max(
                                signal_data["signals"],
                                key=lambda x: x.get("confidence", 0)
                            )
                            
                            signals[symbol] = {
                                "action": best_signal.get("action", "HOLD"),
                                "confidence": best_signal.get("confidence", 0),
                                "timestamp": best_signal.get("timestamp", 0),
                                "price": best_signal.get("price", 0),
                                "reason": best_signal.get("reason", ""),
                            }
                        else:
                            # ê¸°ì¡´ ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬
                            signals[symbol] = signal_data
                            
                except Exception as e:
                    self.logger.error(f"Failed to load signal file {signal_file}: {e}")
                    continue
                    
        except Exception as e:
            self.logger.error(f"Failed to load ARES signals: {e}")
        
        return signals
    
    def load_recent_executions(self) -> List[Dict]:
        """ìµœê·¼ ì²´ê²° ë‚´ì—­ ë¡œë“œ"""
        executions = []
        try:
            orders_file = Path("data/orders_log.ndjson")
            if not orders_file.exists():
                return executions
            
            with open(orders_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
                # ìµœê·¼ 20ê°œ ë¡œë“œ
                recent_lines = lines[-20:] if len(lines) > 20 else lines
                
                for line in recent_lines:
                    try:
                        exec_data = json.loads(line.strip())
                        executions.append(exec_data)
                    except json.JSONDecodeError:
                        continue
                        
        except Exception as e:
            self.logger.error(f"Failed to load recent executions: {e}")
        
        return executions
    
    def get_stale_status(self, data_age_sec: float) -> Tuple[str, str]:
        """Stale ìƒíƒœ ë°˜í™˜"""
        if data_age_sec <= self.stale_threshold:
            return "ğŸŸ¢", "Fresh"
        elif data_age_sec <= self.stale_threshold * 2:
            return "ğŸŸ¡", "Stale"
        else:
            return "ğŸ”´", "Very Stale"
    
    def get_heartbeat_status(self, lag_sec: float) -> Tuple[str, str]:
        """Heartbeat ìƒíƒœ ë°˜í™˜"""
        if lag_sec <= self.heartbeat_threshold:
            return "ğŸŸ¢", "Connected"
        elif lag_sec <= self.heartbeat_threshold * 2:
            return "ğŸŸ¡", "Lagging"
        else:
            return "ğŸ”´", "Disconnected"


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_global_loader: Optional[EnhancedDataLoader] = None


def get_global_loader() -> EnhancedDataLoader:
    """ì „ì—­ ë°ì´í„° ë¡œë” ë°˜í™˜"""
    global _global_loader
    if _global_loader is None:
        _global_loader = EnhancedDataLoader()
    return _global_loader


# Streamlit ìºì‹œ ë°ì½”ë ˆì´í„°ì™€ í˜¸í™˜ë˜ëŠ” ë˜í¼ í•¨ìˆ˜ë“¤
@st.cache_data(ttl=2)
def load_latest_signals_enhanced():
    """í–¥ìƒëœ ARES ì‹ í˜¸ ë¡œë“œ"""
    loader = get_global_loader()
    return loader.load_ares_signals()


@st.cache_data(ttl=1)
def load_recent_executions_enhanced():
    """í–¥ìƒëœ ì²´ê²° ë‚´ì—­ ë¡œë“œ"""
    loader = get_global_loader()
    return loader.load_recent_executions()


@st.cache_data(ttl=1)
def load_databus_snapshot_enhanced():
    """í–¥ìƒëœ databus ìŠ¤ëƒ…ìƒ· ë¡œë“œ"""
    loader = get_global_loader()
    data, integrity = loader.load_databus_snapshot()
    return data, integrity


@st.cache_data(ttl=1)
def load_health_data_enhanced():
    """í–¥ìƒëœ í—¬ìŠ¤ ë°ì´í„° ë¡œë“œ"""
    loader = get_global_loader()
    data, integrity = loader.load_health_data()
    return data, integrity
